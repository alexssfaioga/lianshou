<!DOCTYPE html>
<html><head>
		<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
		<meta http-equiv="Content-Security-Policy" content="default-src 'none'; img-src data:; style-src 'unsafe-inline' data:">
		<title>Zotero 报告</title>
		<link rel="stylesheet" type="text/css" href="data:text/css;base64,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">
		<link rel="stylesheet" type="text/css" media="screen,projection" href="data:text/css;base64,LyogR2VuZXJpYyBzdHlsZXMgKi8KYm9keSB7Cglmb250OiA2Mi41JSBHZW9yZ2lhLCBUaW1lcywgc2VyaWY7Cgl3aWR0aDogNzgwcHg7CgltYXJnaW46IDAgYXV0bzsKfQoKaDIgewoJZm9udC1zaXplOiAxLjVlbTsKCWxpbmUtaGVpZ2h0OiAxLjVlbTsKCWZvbnQtZmFtaWx5OiBHZW9yZ2lhLCBUaW1lcywgc2VyaWY7Cn0KCnAgewoJbGluZS1oZWlnaHQ6IDEuNWVtOwp9CgphOmFueS1saW5rIHsKCWNvbG9yOiAjOTAwOwp9CgphOmhvdmVyLCBhOmFjdGl2ZSB7Cgljb2xvcjogIzc3NzsKfQoKQG1lZGlhIChwcmVmZXJzLWNvbG9yLXNjaGVtZTogZGFyaykgewoJYTphbnktbGluayB7CgkJY29sb3I6ICNmMDA7Cgl9CgoJYTpob3ZlciwgYTphY3RpdmUgewoJCWNvbG9yOiAjOTk5OwoJfQp9CgoKdWwucmVwb3J0IHsKCWZvbnQtc2l6ZTogMS40ZW07Cgl3aWR0aDogNjgwcHg7CgltYXJnaW46IDAgYXV0bzsKCXBhZGRpbmc6IDIwcHggMjBweDsKfQoKLyogTWV0YWRhdGEgdGFibGUgKi8KdGFibGUgewoJYm9yZGVyOiAxcHggI2NjYyBzb2xpZDsKCW92ZXJmbG93OiBhdXRvOwoJd2lkdGg6IDEwMCU7CgltYXJnaW46IC4xZW0gYXV0byAuNzVlbTsKCXBhZGRpbmc6IDAuNWVtOwp9Cg==">
		<link rel="stylesheet" type="text/css" media="print" href="data:text/css;base64,Ym9keSB7Cglmb250OiAxMnB0ICJUaW1lcyBOZXcgUm9tYW4iLCBUaW1lcywgR2VvcmdpYSwgc2VyaWY7CgltYXJnaW46IDA7Cgl3aWR0aDogYXV0bzsKfQoKLyogUGFnZSBCcmVha3MgKHBhZ2UtYnJlYWstaW5zaWRlIG9ubHkgcmVjb2duaXplZCBieSBPcGVyYSkgKi8KaDEsIGgyLCBoMywgaDQsIGg1LCBoNiB7CglwYWdlLWJyZWFrLWFmdGVyOiBhdm9pZDsKCXBhZ2UtYnJlYWstaW5zaWRlOiBhdm9pZDsKfQoKdWwsIG9sLCBkbCB7CglwYWdlLWJyZWFrLWluc2lkZTogYXZvaWQ7Cgljb2xvci1hZGp1c3Q6IGV4YWN0Owp9CgpoMiB7Cglmb250LXNpemU6IDEuM2VtOwoJbGluZS1oZWlnaHQ6IDEuM2VtOwp9CgphIHsKCWNvbG9yOiBpbmhlcml0OwoJdGV4dC1kZWNvcmF0aW9uOiBub25lOwp9Cg==">
	</head>
	<body>
		<ul class="report combineChildItems">
			<li id="item_PASHD2C3" class="item conferencePaper">
			<h2>Deep Manifold Transformation for Protein Representation Learning</h2>
				<table>
					<tbody><tr>
						<th>条目类型</th>
						<td>会议论文</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Bozhen Hu</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Zelin Zang</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Cheng Tan</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Stan Z. Li</td>
					</tr>
					<tr>
					<th>摘要</th>
						<td>Protein representation learning is critical in various tasks 
in biology, such as drug design and protein structure or function 
prediction, which has primarily benefited from protein language models 
and graph neural networks. These models can capture intrinsic patterns 
from protein sequences and structures through masking and task-related 
losses. However, the learned protein representations are usually not 
well optimized, leading to performance degradation due to limited data, 
difficulty adapting to new tasks, etc. To address this, we propose a new
 deep manifold transformation approach for universal protein 
representation learning (DMTPRL). It employs manifold learning 
strategies to improve the quality and adaptability of the learned 
embeddings. Specifically, we apply a novel manifold learning loss during
 training based on the graph inter-node similarity. Our proposed DMTPRL 
method outperforms state-of-the-art baselines on diverse downstream 
tasks across popular datasets. This validates our approach for learning 
universal and robust protein representations. We promise to release the 
code after acceptance.</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2024-04</td>
					</tr>
					<tr>
					<th>文库编目</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>网址</th>
						<td><a href="https://ieeexplore.ieee.org/document/10448342">https://ieeexplore.ieee.org/document/10448342</a></td>
					</tr>
					<tr>
					<th>访问时间</th>
						<td>2025/1/10 19:44:04</td>
					</tr>
					<tr>
					<th>其他</th>
						<td>ISSN: 2379-190X
TLDR: This work proposes a new deep manifold transformation approach for
 universal protein representation learning (DMTPRL), which employs 
manifold learning strategies to improve the quality and adaptability of 
the learned embeddings.</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>1801-1805</td>
					</tr>
					<tr>
					<th>会议论文集标题</th>
						<td>ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</td>
					</tr>
					<tr>
					<th>会议名称</th>
						<td>ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/ICASSP48485.2024.10448342">10.1109/ICASSP48485.2024.10448342</a></td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2025/1/10 19:44:04</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2025/1/10 19:44:05</td>
					</tr>
				</tbody></table>
				<h3 class="tags">标签：</h3>
				<ul class="tags">
					<li>Adaptation models</li>
					<li>Biological system modeling</li>
					<li>manifold learning</li>
					<li>Manifold learning</li>
					<li>Manifolds</li>
					<li>Protein representation learning</li>
					<li>Proteins</li>
					<li>Representation learning</li>
					<li>sequence</li>
					<li>structure</li>
					<li>Training</li>
				</ul>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_JP3PH4SQ">已提交版本					</li>
				</ul>
			</li>


			<li id="item_G8RMGJBY" class="item journalArticle">
			<h2>Interpretable Prediction of SARS-CoV-2 Epitope-Specific TCR Recognition Using a Pre-Trained Protein Language Model</h2>
				<table>
					<tbody><tr>
						<th>条目类型</th>
						<td>期刊文章</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Sunyong Yoo</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Myeonghyeon Jeong</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Subhin Seomun</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Kiseong Kim</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Youngmahn Han</td>
					</tr>
					<tr>
					<th>摘要</th>
						<td>The emergence of the novel coronavirus, designated as severe 
acute respiratory syndrome coronavirus-2 (SARS-CoV-2), has posed a 
significant threat to public health worldwide. There has been progress 
in reducing hospitalizations and deaths due to SARS-CoV-2. However, 
challenges stem from the emergence of SARS-CoV-2 variants, which exhibit
 high transmission rates, increased disease severity, and the ability to
 evade humoral immunity. Epitope-specific T-cell receptor (TCR) 
recognition is key in determining the T-cell immunogenicity for 
SARS-CoV-2 epitopes. Although several data-driven methods for predicting
 epitope-specific TCR recognition have been proposed, they remain 
challenging due to the enormous diversity of TCRs and the lack of 
available training data. Self-supervised transfer learning has recently 
been proven useful for extracting information from unlabeled protein 
sequences, increasing the predictive performance of fine-tuned models, 
and using a relatively small amount of training data. This study 
presents a deep-learning model generated by fine-tuning pre-trained 
protein embeddings from a large corpus of protein sequences. The 
fine-tuned model showed markedly high predictive performance and 
outperformed the recent Gaussian process-based prediction model. The 
output attentions captured by the deep-learning model suggested critical
 amino acid positions in the SARS-CoV-2 epitope-specific TCRβ sequences 
that are highly associated with the viral escape of T-cell immune 
response.</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2024-05</td>
					</tr>
					<tr>
					<th>文库编目</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>网址</th>
						<td><a href="https://ieeexplore.ieee.org/document/10443062">https://ieeexplore.ieee.org/document/10443062</a></td>
					</tr>
					<tr>
					<th>访问时间</th>
						<td>2025/1/10 19:44:13</td>
					</tr>
					<tr>
					<th>其他</th>
						<td>Conference Name: IEEE/ACM Transactions on Computational 
Biology and Bioinformatics
TLDR: A deep-learning model generated by fine-tuning pre-trained protein
 embeddings from a large corpus of protein sequences showed markedly 
high predictive performance and outperformed the recent Gaussian 
process-based prediction model.</td>
					</tr>
					<tr>
					<th>卷次</th>
						<td>21</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>428-438</td>
					</tr>
					<tr>
					<th>刊名</th>
						<td>IEEE/ACM Transactions on Computational Biology and Bioinformatics</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/TCBB.2024.3368046">10.1109/TCBB.2024.3368046</a></td>
					</tr>
					<tr>
					<th>期号</th>
						<td>3</td>
					</tr>
					<tr>
					<th>ISSN</th>
						<td>1557-9964</td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2025/1/10 19:44:13</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2025/1/10 19:44:14</td>
					</tr>
				</tbody></table>
				<h3 class="tags">标签：</h3>
				<ul class="tags">
					<li>Amino acids</li>
					<li>Attention mechanism</li>
					<li>Attention mechanisms</li>
					<li>Coronaviruses</li>
					<li>deep learning</li>
					<li>Deep learning</li>
					<li>epitope</li>
					<li>Immune system</li>
					<li>Lymphocytes</li>
					<li>Predictive models</li>
					<li>Proteins</li>
					<li>SARS-CoV-2</li>
					<li>T-cell receptor</li>
				</ul>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_RP8FNQEY">Full Text PDF					</li>
					<li id="item_292MN5K8">IEEE Xplore Abstract Record					</li>
				</ul>
			</li>


			<li id="item_Q9FXSSRG" class="item conferencePaper">
			<h2>MSP: A Multi-level Structures-based Framework with Multi-level Pre-training for Protein-Ligand Binding Affinity Prediction</h2>
				<table>
					<tbody><tr>
						<th>条目类型</th>
						<td>会议论文</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Ruikang Li</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Jiaxian Yan</td>
					</tr>
					<tr>
						<th class="author">作者</th>
						<td>Kai Zhang</td>
					</tr>
					<tr>
					<th>摘要</th>
						<td>A protein structure exhibits a multi-level architecture 
(including atomic, residue, and secondary structure levels), each of 
which possesses distinct characteristics and information. Effectively 
extracting and utilizing the information embedded within these 
multi-level structures is crucial for accurately predicting 
protein-ligand binding affinity (PLBA). However, existing approaches 
primarily focus on utilizing information from individual levels of 
protein structure, neglecting the potential advantages of considering 
multiple levels simultaneously. To overcome this challenge, we are the 
first to propose a novel multi-level structure-based affinity prediction
 framework called MSP. MSP utilizes protein atomic and residue level 
structures to directly model atom(protein)-atom(ligand) interactions and
 residue(protein)-atom(ligand) interactions involved in protein-ligand 
binding. Additionally, it incorporates secondary structure information 
through a supervised auxiliary task. Finally, a late fusion approach is 
applied to fuse information from multi-level structures to make the 
prediction. Extensive experiments on PLBA benchmark datasets demonstrate
 that MSP surpasses state-of-the-art methods in both prediction accuracy
 and generalization ability. To further improve the performance and 
interpretability of the MSP framework. We also propose a novel 
contrastive learning self-supervised pre-training task. Based on the 
above framework, we have designed pre-training tasks for 
atom(protein)-atom(ligand) interactions and 
residue(protein)-atom(ligand) interactions respectively, and 
demonstrated the effectiveness of these pre-training tasks.</td>
					</tr>
					<tr>
					<th>日期</th>
						<td>2024-07</td>
					</tr>
					<tr>
					<th>短标题</th>
						<td>MSP</td>
					</tr>
					<tr>
					<th>文库编目</th>
						<td>IEEE Xplore</td>
					</tr>
					<tr>
					<th>网址</th>
						<td><a href="https://ieeexplore.ieee.org/document/10743158">https://ieeexplore.ieee.org/document/10743158</a></td>
					</tr>
					<tr>
					<th>访问时间</th>
						<td>2025/1/10 19:42:37</td>
					</tr>
					<tr>
					<th>其他</th>
						<td>TLDR: A novel multi-level structure-based affinity prediction 
framework called MSP is proposed, which surpasses state-of-the-art 
methods in both prediction accuracy and generalization ability and 
proposes a novel contrastive learning self-supervised pre-training task.</td>
					</tr>
					<tr>
					<th>页码</th>
						<td>57-63</td>
					</tr>
					<tr>
					<th>会议论文集标题</th>
						<td>2024 International Conference on Computational Linguistics and Natural Language Processing (CLNLP)</td>
					</tr>
					<tr>
					<th>会议名称</th>
						<td>2024 International Conference on Computational Linguistics and Natural Language Processing (CLNLP)</td>
					</tr>
					<tr>
					<th>DOI</th>
						<td><a href="http://doi.org/10.1109/CLNLP64123.2024.00019">10.1109/CLNLP64123.2024.00019</a></td>
					</tr>
					<tr>
					<th>添加日期</th>
						<td>2025/1/10 19:42:37</td>
					</tr>
					<tr>
					<th>修改日期</th>
						<td>2025/1/10 19:42:38</td>
					</tr>
				</tbody></table>
				<h3 class="tags">标签：</h3>
				<ul class="tags">
					<li>Benchmark testing</li>
					<li>Computational linguistics</li>
					<li>Computer architecture</li>
					<li>Contrastive learning</li>
					<li>Contrastive Learning</li>
					<li>Data mining</li>
					<li>Drug discovery</li>
					<li>Fuses</li>
					<li>Index Terms: Drug discovery</li>
					<li>Indexes</li>
					<li>Natural language processing</li>
					<li>Pre-training</li>
					<li>Protein Multi-level Structures</li>
					<li>Protein-Ligand Binding Affinity Prediction</li>
					<li>Proteins</li>
				</ul>
				<h3 class="attachments">附件</h3>
				<ul class="attachments">
					<li id="item_LGEPZE96">IEEE Xplore Abstract Record					</li>
				</ul>
			</li>

		</ul>
	
</body></html>